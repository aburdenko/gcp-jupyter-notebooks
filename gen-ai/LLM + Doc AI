{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"14xmkn6KjYliNgOz-CyIjfpeP0d3vGc5k","timestamp":1709240411384},{"file_id":"13LZMrj3RFNZo5CDq_iMLTUI60jqtMElR","timestamp":1687793994588}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"359697d5"},"source":["# Document Q & A with Document AI and LangChain\n","---\n","\n","**Document AI üìëüëÄ + LangChain ü¶úÔ∏èüîó + ScaNN / Matching Engine üß©üîç**\n","\n","---\n","\n","| | |\n","|----------|-------------|\n","| Author(s)   | Alex Burdenko |\n","| Last updated | 2/29/2024 |\n"]},{"cell_type":"markdown","source":["\n","## Objective\n","\n","This notebook demonstrates how you to parse private and public documents with Document AI and process the output metadata (e.g. tables, paragraphs, images) efficiently for Retrieval Q & A using LangChain ü¶úÔ∏èüîó. By default, ScaNN or Vertex AI Matching Engine is used in this notebook as the vector store for embeddings generated using PaLM-Gecko ü¶é.\n","\n","Each component in this workflow from the embedding generator to the vector store to the LLM used in the retrieval Q & A chain is interchangeable and can be swapped with an off-the-shelf [component](https://python.langchain.com/docs/modules/) supported by LangChain.\n","\n","## Costs\n","\n","This tutorial uses billable components of Google Cloud Platform (GCP):\n","\n","-   [Vertex AI LLM APIs](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)\n","-   [Vertex AI Matching Engine [optional]](https://cloud.google.com/vertex-ai/pricing#matchingengine)\n","-   [Cloud Storage [optional]](https://cloud.google.com/storage)"],"metadata":{"id":"fK2g6SbHdUn1"}},{"cell_type":"markdown","source":["## Install dependencies"],"metadata":{"id":"40hvToVo7DR_"}},{"cell_type":"code","source":["import sys\n","import subprocess\n","import pkg_resources\n","\n","#'google-cloud-aiplatform==1.26.1'\n","\n","# , 'Pillow==9.5.0'\n","#   , 'PyCryptodome'\n","\n","required = {\n","   'google-cloud-aiplatform'\n","  , 'google-cloud-documentai==2.16.0'\n","  , 'scann==1.2.9'\n","  , 'langchain==0.0.214'\n","  , 'pypdf==3.11.0'\n","  , 'gradio==3.35.2'\n","  , 'matplotlib==3.7.1'\n","  , 'shapely==1.8.5'\n","  , 'google-cloud-documentai'\n","  , 'google-auth'\n","}\n","\n","print(f\"working set entries: {pkg_resources.working_set}\")\n","\n","specific_required = set()\n","\n","for pkg in required:\n","  if not '==' in pkg and pkg in pkg_resources.working_set.by_key.keys():\n","    str_key=str( pkg_resources.get_distribution(pkg) ).replace(' ','==')\n","    print(f\"adding {str_key}\")\n","    specific_required.add(str_key)\n","  else:\n","    specific_required.add(pkg)\n","\n","required=specific_required\n","\n","required.discard(None)\n","installed = { f\"{pkg.key}=={pkg_resources.get_distribution(pkg.key).version}\" for pkg in pkg_resources.working_set}\n","missing = required - installed\n","print(f\"required: {required}\")\n","print(f\"installed: {installed}\")\n","#missing = (required - installed) | missing\n","print(f\"missing: {missing}\")\n","if missing:\n","    python = sys.executable\n","    print(f\"installing...\")\n","    #subprocess.check_call([python, '-m', 'pip', 'install', '--upgrade', f\"--target={PYTHON_LIB_PATH}\", *missing], stdout=subprocess.DEVNULL)\n","    subprocess.check_call([python, '-m', 'pip', 'install', '--upgrade', *missing], stdout=subprocess.DEVNULL)\n","    print(f\"done.\")\n","\n","    import IPython\n","    import time\n","    print( 'restarting kernel...' )\n","    app = IPython.Application.instance()\n","    app.kernel.do_shutdown(False)\n","\n","    # Wait for the kernel to \"crash\". Haven't found a more elegant workaround for do_shutdown being an async call..."],"metadata":{"id":"6-0lAZPunrvI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Initialize environment\n","\n","Note: During Q & A, signed URLs will be served that reference the relevant matches used for summarization by the LLM. As a result, a service account will be used that signs the URLs (this step cannot be performed using user credentials)."],"metadata":{"id":"IggwzaHknI5_"}},{"cell_type":"code","source":["PROJECT_ID = \"\" # @param {type:\"string\"} <---CHANGE THESE\n","%env PROJECT_ID=$PROJECT_ID\n","!gcloud config set project $PROJECT_ID --quiet\n","\n","BUCKET_NAME = \" # @param {type:\"string\"} <---CHANGE THESE\n","%env BUCKET_NAME=$BUCKET_NAME\n","\n","BUCKET_URI = f\"gs://{BUCKET_NAME}\"\n","\n","\n","REGION = \"us-central1\" # @param {type:\"string\"} <---CHANGE THESE\n","LOCATION = \"us\" # @param {type:\"string\"} <---CHANGE THESE\n","\n","USE_SERVICE_ACCOUNT=True #@param {type: \"boolean\"}\n","\n","GCS_URL = \"\" # @param {type:\"string\"} <---CHANGE THESE\n","\n","PROCESSOR_ID = '' # @param {type:\"string\"}\n","%env PROCESSOR_ID=$PROCESSOR_ID\n","\n","# LLM model\n","MODEL_NAME = \"text-bsion-32k-tuned-model\" #@param {type: \"string\"}\n","max_output_tokens = 256 #@param {type: \"integer\"}\n","temperature = 0 #@param {type: \"number\"}\n","top_p = 1 #@param {type: \"number\"}\n","top_k = 40 #@param {type: \"number\"}\n","verbose = True #@param {type: \"boolean\"}\n","\n","\n","template_path = \"https://us-kfp.pkg.dev/ml-pipeline/large-language-model-pipelines/tune-large-model/v2.0.0\" #@param {type: \"string\"}\n","!unset GOOGLE_APPLICATION_CREDENTIALS\n","!unset SIGNING_SERVICE_ACCOUNT\n","\n","%reload_ext autoreload\n","%autoreload 2\n"],"metadata":{"id":"mzLNceYG6iuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user(clear_output=False)"],"metadata":{"id":"FoHt2G-XBpwy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"-fDj8AaIBQZs"}},{"cell_type":"code","source":["import sys\n","import os\n","\n","FILE_EXISTS=os.path.exists( '/content/service_account.json' )\n","IN_COLAB = 'google.colab' in sys.modules\n","%env IN_COLAB=$IN_COLAB\n","\n","if USE_SERVICE_ACCOUNT:\n","  if IN_COLAB and not FILE_EXISTS:\n","    from google.colab import files\n","\n","    uploaded = files.upload()\n","\n","    for fn in uploaded.keys():\n","      txt = \"User uploaded file {name} with length {length} bytes\".format( name=fn, length=len(uploaded[fn]))\n","      print( txt )\n","\n","    import os\n","    os.rename(f\"/content/{fn}\",'/content/service_account.json')\n","    GOOGLE_APPLICATION_CREDENTIALS=\"/content/service_account.json\"\n","    %env GOOGLE_APPLICATION_CREDENTIALS=$GOOGLE_APPLICATION_CREDENTIALS\n","\n","\n","    # Grant Service Account Token Creator role on the signing service acocunt\n","    GOOGLE_CLOUD_SERVICE_ACCOUNT=fn.rsplit('.', 1)[0]\n","    %env GOOGLE_CLOUD_SERVICE_ACCOUNT=$GOOGLE_CLOUD_SERVICE_ACCOUNT\n","    !gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS\n","\n","import google.auth\n","credentials, project = google.auth.default()\n","# Add the cloud-platform scope to the credentials.\n","credentials = credentials.with_scopes([\"https://www.googleapis.com/auth/cloud-platform\"])\n","\n","print(credentials)\n","from google.cloud.bigquery import magics\n","magics.context.credentials = credentials\n","\n","\n"],"metadata":{"id":"zFGBtToxj3oD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Enable APIs\n","\n","Skip step if APIs are already enabled and user account has __Service Account Token Creator__ role on the signing service account.\n","\n","If APIs are not already enabled, you will be prompted to login again but this time through the _!gcloud auth login_, so gcloud commands can be executed. This step __only__ has to be executed once (if requirements aren't already met) üòÑ"],"metadata":{"id":"OLe38ruNp-QP"}},{"cell_type":"code","source":["#!gcloud auth application-default login -q\n","#!gcloud auth application-default set-quota-project {PROJECT_ID}\n","#!gcloud config set project {PROJECT_ID}\n","\n","# Enable Document AI\n","!gcloud services enable documentai.googleapis.com --quiet\n","\n","# Enable Vertex AI\n","!gcloud services enable aiplatform.googleapis.com --quiet\n","\n","# Enable IAM Credentials API\n","!gcloud services enable iamcredentials.googleapis.com --quiet"],"metadata":{"id":"qusYjPGvo9ft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ensure your user account has the ability to sign URLs using the service account."],"metadata":{"id":"t-vEOVPRwGEp"}},{"cell_type":"code","source":["!gcloud iam service-accounts add-iam-policy-binding $GOOGLE_CLOUD_SERVICE_ACCOUNT \\\n","  --member=serviceAccount:$GOOGLE_CLOUD_SERVICE_ACCOUNT \\\n","  --role=roles/iam.serviceAccountTokenCreator \\\n","  --billing-project $PROJECT_ID \\\n","  --project $PROJECT_ID \\\n","  -q"],"metadata":{"id":"9Wj-XJmyqCyA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import packages"],"metadata":{"id":"AbGyl5s7CDf-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrbDu8NzmGqw"},"outputs":[],"source":["import concurrent.futures\n","import datetime\n","import gradio as gr\n","import IPython\n","import numpy as np\n","import os\n","import pandas as pd\n","import PIL, PIL.ImageDraw\n","import requests\n","import scann\n","import shapely\n","import time\n","import tempfile\n","import threading\n","import vertexai\n","from io import BytesIO\n","from google.api_core.client_options import ClientOptions\n","from google.auth import default\n","from google.auth import impersonated_credentials\n","from google.cloud import documentai, storage\n","\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.docstore.document import Document\n","from langchain.document_loaders.base import BaseLoader\n","from langchain.document_loaders.unstructured import UnstructuredFileLoader\n","from langchain.embeddings.base import Embeddings\n","from langchain.embeddings import VertexAIEmbeddings\n","from langchain.llms import BaseLLM, VertexAI\n","from langchain.prompts import PromptTemplate\n","from langchain.schema import Document\n","from langchain.vectorstores.base import VectorStore\n","from langchain.vectorstores import MatchingEngine\n","from pypdf import PdfReader, PdfWriter\n","from tqdm import tqdm\n","from typing import Any, Iterable, List, Optional, Sequence, Tuple, Type\n","from urllib.parse import urlparse"]},{"cell_type":"markdown","source":["## LangChain wrapper utilities\n","\n","**Run the following cells**\n","\n","* Custom SourceDocument\n","* Custom DocAI DocumentLoader\n","* Custom ScaNN VectorStore\n","* DocumentBot"],"metadata":{"id":"WQC8jQYrwAUV"}},{"cell_type":"code","source":["# @title\n","class SourceDocument:\n","    \"\"\"Document Metadata for DocAILoader\"\"\"\n","\n","    def __init__(self, content: Optional[bytes], mime_type: str, source: str, page: Optional[int] = None, **kwargs):\n","        \"\"\"Initialize with content, mime type, source, and optional page\"\"\"\n","        super().__init__(**kwargs)\n","        self.content = content\n","        self.mime_type = mime_type\n","        self.source = source\n","        self.page = page\n","        self.document = None\n","\n","    def set_document(self, document: documentai.Document) -> None:\n","        self.content = None\n","        self.document = document"],"metadata":{"id":"rN4j5mgfrfRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DocAILoader(BaseLoader):\n","    \"\"\"Loading logic for loading documents from GCS.\"\"\"\n","\n","    def __init__(\n","        self,\n","        sources: List[str],\n","        project_id: str,\n","        location: str = \"us\",\n","        processor_id: str = None,\n","        default_processor_display_name: str = \"doc-search-form-parser\",\n","        default_processor_type: str = \"FORM_PARSER_PROCESSOR\",\n","        default_processor_version: str = \"pretrained-form-parser-v1.0-2020-09-23\",\n","        create_processor_if_not_exists: bool = True,\n","        max_doc_ai_requests_per_min: int = 96,\n","        max_parallel_doc_ai_requests: int = 8,\n","        verbose: bool = True\n","    ) -> None:\n","      \"\"\"\n","      Initialize\n","\n","      Args:\n","        sources (List[str]): List of source documents\n","        project_id (str): Project ID\n","        location (str): Location of the project\n","        processor_id (str): Processor ID\n","        default_processor_display_name (str): Default processor display name\n","        default_processor_type (str): Default processor type\n","        default_processor_version (str): Default processor version\n","        create_processor_if_not_exists (bool): Create processor if it does not exist\n","        max_doc_ai_requests_per_min (int): Max parallel document AI requests\n","        max_parallel_doc_ai_requests (int): Max parallel document AI requests\n","        verbose (bool): Verbose\n","      Returns:\n","        None\n","      \"\"\"\n","      self.sources = sources\n","      self.project_id = project_id\n","      self.location = location\n","      self.processor_id = processor_id\n","      self.default_processor_display_name = default_processor_display_name\n","      self.default_processor_type = default_processor_type\n","      self.default_processor_version = default_processor_version\n","      self.create_processor_if_not_exists = create_processor_if_not_exists\n","      self.max_doc_ai_requests_per_min = max_doc_ai_requests_per_min\n","      self.max_parallel_doc_ai_requests = max_parallel_doc_ai_requests\n","      self.verbose = verbose\n","      self.processor_name = None\n","      self.doc_ai_api_calls = np.array([])\n","      self.active_calls = 0\n","      self.lock = threading.Lock()\n","\n","    def set_processor(self) -> None:\n","      \"\"\"\n","      Set processor\n","\n","      Args:\n","        processor_id (str): Processor ID\n","\n","      Returns:\n","        None\n","      \"\"\"\n","\n","      if self.processor_id is None:\n","        opts = ClientOptions(api_endpoint=f\"{self.location}-documentai.googleapis.com\")\n","        client = documentai.DocumentProcessorServiceClient(client_options=opts)\n","        parent = client.common_location_path(self.project_id, self.location)\n","\n","        self.processor_name = None\n","        # check if processor already exists\n","        processor_list = client.list_processors(parent=parent)\n","        for processor in processor_list:\n","          if processor.display_name == self.default_processor_display_name:\n","            self.processor_name = processor.name\n","            if self.verbose is True:\n","              print(f'Set processor \"{self.processor_name}\" ‚úì')\n","            break\n","\n","        if self.processor_name is None and self.create_processor_if_not_exists:\n","          if self.verbose is True:\n","            print(f'Creating new processor of type \"{self.default_processor_type}\"' +\n","                  f' with display name \"{self.default_processor_display_name}\"...')\n","          # create a processor\n","          processor = client.create_processor(\n","            parent=parent,\n","            processor=documentai.Processor(\n","                display_name=self.default_processor_display_name,\n","                type_=self.default_processor_type,\n","                default_processor_version=self.default_processor_version\n","            ),\n","          )\n","          self.processor_name = processor.name\n","          if self.verbose is True:\n","            print(f'Created and set processor \"{self.processor_name}\" ‚úì')\n","      else:\n","        self.processor_name = (\n","            f\"projects/{self.project_id}/locations/{self.location}/processors/{self.processor_id}\"\n","        )\n","\n","    def _process_gcs_uri(self, uri: str) -> Sequence[str]:\n","      \"\"\"\n","      Deconstruct GCS URI into scheme, bucket, path and file\n","\n","      Args:\n","          uri (str): GCS URI\n","\n","      Returns:\n","          scheme (str): URI scheme\n","          bucket (str): URI bucket\n","          path (str): URI path\n","          filename (str): URI file\n","      \"\"\"\n","      url_arr = uri.split(\"/\")\n","      if \".\" not in url_arr[-1]:\n","          filename = \"\"\n","      else:\n","          filename = url_arr.pop()\n","      scheme = url_arr[0]\n","      bucket = url_arr[2]\n","      path = \"/\".join(url_arr[3:])\n","      path = path[:-1] if path.endswith(\"/\") else path\n","      return scheme, bucket, path, filename\n","\n","    def _is_url(self, string):\n","      parsed = urlparse(string)\n","      return parsed.scheme and parsed.netloc\n","\n","    def _get_mime_type(self, filename: str):\n","      \"\"\"\n","      Get MIME type\n","\n","      Args:\n","        filename (str): URI or file name.\n","\n","      Returns:\n","        mime_type (str)\n","      \"\"\"\n","      mime_type = 'application/pdf'\n","      if filename.lower().endswith(\"pdf\"):\n","          mime_type = \"application/pdf\"\n","      elif filename.lower().endswith(\"tiff\") or filename.endswith(\"tif\"):\n","          mime_type = \"image/tiff\"\n","      elif filename.lower().endswith(\"jpeg\") or filename.lower().endswith(\"jpg\"):\n","          mime_type = \"image/jpeg\"\n","      elif filename.lower().endswith(\"png\"):\n","          mime_type = \"image/png\"\n","      elif filename.lower().endswith(\"bmp\"):\n","          mime_type = \"image/bmp\"\n","      elif filename.lower().endswith(\"webp\"):\n","          mime_type = \"image/webp\"\n","\n","      return mime_type\n","\n","    def _get_docs_from_sources(self, sources: Sequence[str]):\n","      \"\"\"\n","      Get docs from sources\n","\n","      Args:\n","        sources (Sequence[str]): List of GCS URIs and website URLs\n","\n","      Returns:\n","        docs (List[Document]): SourceDocuments\n","      \"\"\"\n","\n","      # initialize storage client\n","      storage_client = storage.Client()\n","\n","      docs = []\n","      for source in sources:\n","          if source.startswith('gs://'):\n","              scheme, bucket, path, filename = self._process_gcs_uri(source)\n","              # create a bucket object for our bucket\n","              bucket = storage_client.get_bucket(bucket)\n","              # create a blob object from the filepath\n","              blob = bucket.blob(os.path.join(path, filename))\n","\n","              if blob.exists():\n","                # get content bytes\n","                content = blob.download_as_bytes()\n","                if blob.content_type == \"application/pdf\":\n","                  pdf_reader = PdfReader(BytesIO(content))\n","                  for index, page in enumerate(pdf_reader.pages):\n","                    pdf_writer = PdfWriter()\n","                    pdf_writer.add_page(page)\n","                    response_bytes_stream = BytesIO()\n","                    pdf_writer.write(response_bytes_stream)\n","                    content = response_bytes_stream.getvalue()\n","\n","                    # define source document\n","                    doc = SourceDocument(content=content, mime_type=blob.content_type, source=source, page=index + 1)\n","                    docs.append(doc)\n","                else:\n","                  # define source document\n","                  doc = SourceDocument(content=content, mime_type=blob.content_type, source=source)\n","                  docs.append(doc)\n","\n","              else:\n","                raise ValueError(f'Source \"{source}\" does not exist.')\n","\n","          elif self._is_url(source):\n","            # fetch content\n","            content = requests.get(source).content\n","\n","            # get mime type\n","            mime_type = self._get_mime_type(source)\n","\n","            if mime_type == \"application/pdf\":\n","              pdf_reader = PdfReader(BytesIO(content))\n","              for index, page in enumerate(pdf_reader.pages):\n","                pdf_writer = PdfWriter()\n","                pdf_writer.add_page(page)\n","                response_bytes_stream = BytesIO()\n","                pdf_writer.write(response_bytes_stream)\n","                content = response_bytes_stream.getvalue()\n","\n","                # define source document\n","                doc = SourceDocument(content=content, mime_type=mime_type, source=source, page=index + 1)\n","                docs.append(doc)\n","            else:\n","              # define source document\n","              doc = SourceDocument(content=content, mime_type=mime_type, source=source)\n","              docs.append(doc)\n","          else:\n","              raise ValueError(f'Source \"{source}\" is not valid.')\n","\n","      return docs\n","\n","    def _process_doc_rate_limiter(self) -> None:\n","      \"\"\"Process doc rate limiter\"\"\"\n","      import math\n","\n","      # ensure thread safety\n","      with self.lock:\n","          current_time = time.time()\n","          last_minute_calls = self.doc_ai_api_calls[self.doc_ai_api_calls >= current_time - 60]\n","\n","          # check the number of API calls within the sliding window\n","          while len(last_minute_calls) >= self.max_doc_ai_requests_per_min:\n","              # wait_time = last_minute_calls[-1] + 60 - current_time\n","              wait_time = last_minute_calls[math.ceil((len(last_minute_calls) - 1) / 2)] + 60 - current_time\n","              time.sleep(wait_time)\n","\n","          while self.active_calls >= self.max_parallel_doc_ai_requests:\n","              time.sleep(.5)\n","\n","          # add the current timestamp to the list of API calls\n","          self.active_calls += 1\n","          current_time = time.time()\n","          self.doc_ai_api_calls = np.append(self.doc_ai_api_calls, current_time)\n","\n","    def process_doc(self, doc: SourceDocument) -> documentai.Document:\n","      \"\"\"\n","      Process doc\n","\n","      Args:\n","        doc (SourceDocument): SourceDocument\n","\n","      Returns:\n","        result.document (documentai.Document)\n","      \"\"\"\n","      # Rate limit the API calls\n","      self._process_doc_rate_limiter()\n","\n","      # initialize Document AI client\n","      opts = ClientOptions(api_endpoint=f\"{self.location}-documentai.googleapis.com\")\n","      client = documentai.DocumentProcessorServiceClient(client_options=opts)\n","\n","      # configure the process request\n","      raw_document = documentai.RawDocument(content=doc.content, mime_type=doc.mime_type)\n","      processor_version_name = os.path.join(self.processor_name, \"processorVersions\", self.default_processor_version)\n","      request = documentai.ProcessRequest(name=processor_version_name, raw_document=raw_document)\n","\n","      # process the document\n","      # For a full list of `Document` object attributes, reference this page:\n","      # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\n","      result = client.process_document(request=request)\n","\n","      return result.document\n","\n","    def _process_sources(self, max_workers: Optional[int] = None) -> List[SourceDocument]:\n","      \"\"\"\n","      Process sources\n","\n","      Args:\n","        max_workers (Optional[int], optional): Maximum number of workers. Defaults to None.\n","\n","      Returns:\n","        results (List[documentai.Document]): Documents\n","      \"\"\"\n","      # get docs\n","      docs = self._get_docs_from_sources(self.sources)\n","\n","      # initialize empty results\n","      results = [None] * len(docs)\n","\n","      if not max_workers:\n","          max_workers = len(docs)\n","\n","      # create thread pool with a max number of workers\n","      start_time = time.time()\n","      with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n","          # submit each doc processing task to the thread pool\n","          future_to_doc = {executor.submit(self.process_doc, doc): (index, doc) for index, doc in enumerate(docs)}\n","\n","          # Use tqdm to create a progress bar\n","          with tqdm(total=len(future_to_doc), position=0, leave=True) as progress_bar:\n","\n","            # process the completed tasks as they finish\n","            for future in concurrent.futures.as_completed(future_to_doc):\n","                index, doc = future_to_doc[future]\n","                doc.set_document(future.result())\n","                results[index] = doc\n","                self.active_calls -= 1\n","                # update the progress bar\n","                progress_bar.update(1)\n","\n","      end_time = time.time()\n","      time_lapse = end_time - start_time\n","      time_lapse_mins = round(time_lapse / 60, 3)\n","      if self.verbose is True:\n","        print(f'Processed {len(sources)} source(s) and got {len(results)} result(s) in {time_lapse_mins} mins.  ‚úì')\n","\n","      return results\n","\n","    def load(self, max_workers: Optional[int] = None) -> Tuple[List[Document], dict[Tuple[str, str]: bytes]]:\n","      \"\"\"\n","      Load documents\n","\n","      Args:\n","        max_workers (Optional[int], optional): Maximum number of workers. Defaults to None.\n","\n","      Returns:\n","        documents (List[Document]): Documents\n","        images (dict[Tuple[str, str]]: bytes]): Images\n","      \"\"\"\n","      self.set_processor()\n","\n","      # get results\n","      results = self._process_sources(max_workers=max_workers)\n","\n","      documents = []\n","      images = {}\n","      for result in results:\n","\n","        images.setdefault((result.source, result.page), result.document.pages[0].image.content)\n","\n","        # create documents from detected tables on page\n","        table_documents = []\n","        for table_index, detected_table in enumerate(result.document.pages[0].tables):\n","            text_segments = []\n","            for text_segment in detected_table.layout.text_anchor.text_segments:\n","              text_segments.append({\"start_index\": text_segment.start_index, \"end_index\": text_segment.end_index})\n","            text_segments_df = pd.DataFrame(text_segments)\n","            text_segments_df.sort_values([\"start_index\"], inplace=True)\n","            text_segments_df[\"text\"] = text_segments_df.apply(lambda x: result.document.text[x.start_index: x.end_index], axis=1)\n","\n","            vertices = []\n","            for vertex in detected_table.layout.bounding_poly.vertices:\n","              vertices.append({\"x\": vertex.x, \"y\": vertex.y})\n","\n","            document = Document(\n","                page_content='\\n'.join(text_segments_df[\"text\"]),\n","                metadata={\n","                    \"page\": result.page,\n","                    \"table\": table_index + 1,\n","                    \"mime_type\": result.mime_type,\n","                    \"source\": result.source,\n","                    \"vertices\": vertices\n","                }\n","            )\n","            table_documents.append(document)\n","\n","        documents.extend(table_documents)\n","\n","        # create documents from detected blocks on page\n","        for block_index, detected_block in enumerate(result.document.pages[0].blocks):\n","            text_segments = []\n","            for text_segment in detected_block.layout.text_anchor.text_segments:\n","              text_segments.append({\"start_index\": text_segment.start_index, \"end_index\": text_segment.end_index})\n","            text_segments_df = pd.DataFrame(text_segments)\n","            text_segments_df.sort_values([\"start_index\"], inplace=True)\n","            text_segments_df[\"text\"] = text_segments_df.apply(lambda x: result.document.text[x.start_index: x.end_index], axis=1)\n","\n","            vertices = []\n","            for vertex in detected_block.layout.bounding_poly.vertices:\n","              vertices.append({\"x\": vertex.x, \"y\": vertex.y})\n","            block_shape = shapely.geometry.Polygon([(vertex['x'], vertex['y']) for vertex in vertices])\n","\n","            # only use blocks that are not within table boundaries\n","            add_block = True\n","            for table_document in table_documents:\n","              table_shape = shapely.geometry.Polygon([(vertex['x'], vertex['y']) for vertex in table_document.metadata[\"vertices\"]])\n","              if block_shape.intersects(table_shape):\n","                add_block = False\n","\n","            if add_block:\n","              document = Document(\n","                  page_content=''.join(text_segments_df[\"text\"]),\n","                  metadata={\n","                      \"page\": result.page,\n","                      \"block\": block_index + 1,\n","                      \"mime_type\": result.mime_type,\n","                      \"source\": result.source,\n","                      \"vertices\": vertices\n","                  }\n","              )\n","              documents.append(document)\n","\n","      if self.verbose is True:\n","        print(f'Loaded {len(documents)} document(s) and {len(images)} image(s)  ‚úì')\n","\n","      return documents, images"],"metadata":{"id":"batYZ60WqpAs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ScaNN(VectorStore):\n","    \"\"\"\n","    This class is a wrapper around the ScaNN Vector Similarity Search library.\n","\n","    To use, you should have the ``scann`` python package installed.\n","\n","    References:\n","\n","    https://github.com/google-research/google-research/tree/master/scann\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        embedding_function: Optional[Embeddings] = None,\n","        max_embedding_requests_per_min: int = 300,\n","        verbose: bool = True\n","    ) -> None:\n","        \"\"\"Initialize the ScaNN vector store\"\"\"\n","        if embedding_function is None:\n","          embedding_function = VertexAIEmbeddings()\n","        self._embedding_function = embedding_function\n","        self._searcher = None\n","        self.max_embedding_requests_per_min = max_embedding_requests_per_min\n","        self.verbose = verbose\n","        self.embedding_api_calls = np.array([])\n","        self.lock = threading.Lock()\n","\n","    def _embedding_rate_limiter(self) -> None:\n","      \"\"\"Embedding rate limiter\"\"\"\n","\n","      # ensure thread safety\n","      with self.lock:\n","          current_time = time.time()\n","\n","          self.embedding_api_calls = self.embedding_api_calls[self.embedding_api_calls >= current_time - 60]\n","\n","          # check the number of API calls within the sliding window\n","          if len(self.embedding_api_calls) >= self.max_embedding_requests_per_min:\n","              # if the limit is reached, calculate the remaining time until the next API call is allowed\n","              next_call_time = self.embedding_api_calls[0] + 60\n","              wait_time = next_call_time - current_time\n","              if wait_time > 0:\n","                  time.sleep(wait_time)\n","\n","          # add the current timestamp to the list of API calls\n","          self.embedding_api_calls = np.append(self.embedding_api_calls, current_time)\n","\n","    def _embed_query(self, query: str, index: Optional[int] = None) -> List:\n","      \"\"\"\n","      Embed query\n","\n","      Args:\n","        query (str): Query to embed\n","        index (Optional[int]): Index of the query\n","\n","      Returns:\n","        index (Optional[int]): Index of the query\n","        embeddings (List): Embeddings\n","      \"\"\"\n","      self._embedding_rate_limiter()\n","      embedding = self._embedding_function.embed_query(query)\n","      return index, embedding\n","\n","    def embed_texts(self, texts: List[str], max_workers: Optional[int] = None) -> List[list]:\n","      \"\"\"\n","      Embed texts\n","\n","      Args:\n","        texts (List[str]): Texts to embed\n","        max_workers (Optional[int]): Maximum number of workers to use\n","\n","      Returns:\n","        results (List[list]): Embeddings\n","      \"\"\"\n","      # initialize empty results\n","      results = [None] * len(texts)\n","\n","      if not max_workers:\n","          max_workers = len(texts)\n","\n","      # create thread pool with a max number of workers\n","      start_time = time.time()\n","      with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n","          # submit each doc processing task to the thread pool\n","          futures = [executor.submit(self._embed_query, text, index) for index, text in enumerate(texts)]\n","\n","          # Use tqdm to create a progress bar\n","          with tqdm(total=len(futures), position=0, leave=True) as progress_bar:\n","\n","            # process the completed tasks as they finish\n","            for future in concurrent.futures.as_completed(futures):\n","                index, embedding = future.result()\n","                results[index] = embedding\n","\n","                # update the progress bar\n","                progress_bar.update(1)\n","\n","      end_time = time.time()\n","      time_lapse = end_time - start_time\n","      time_lapse_mins = round(time_lapse / 60, 3)\n","\n","      if self.verbose is True:\n","        print(f'Embedded {len(documents)} documents(s) in {time_lapse_mins} mins. ‚úì')\n","\n","      return results\n","\n","    def add_texts(\n","        self,\n","        texts: Iterable[str],\n","        num_neighbors: int = 10,\n","        distance_function: str = \"dot_product\",\n","        num_leaves: Optional[int] = None,\n","        num_leaves_to_search: Optional[int] = None,\n","        training_sample_size: Optional[int] = None,\n","        dimensions_per_block: int = 2,\n","        anisotropic_quantization_th: Optional[float] = 0.2,\n","        reorder_count: Optional[int] = None,\n","        **kwargs: Any,\n","    ) -> List[str]:\n","        \"\"\"\n","        Generate embeddings and add to the vectorstore\n","\n","        Args:\n","            texts (Iterable[str]): Texts to add to the vectorstore.\n","            num_neighbors (int, optional): Number of neighbors to consider during partitioning. Defaults to 10.\n","            distance_function (str): Distance function to use. Defaults to \"dot_product\".\n","            num_leaves (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            num_leaves_to_search (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            training_sample_size (Optional[int], optional): Number of documents to use for training. Defaults to None.\n","            dimensions_per_block (int, optional): Number of dimensions per block. Defaults to 2.\n","            anisotropic_quantization_th (Optional[float], optional): Anisotropic quantization threshold. Defaults to 0.2.\n","            reorder_count (Optional[int], optional): Number of reorders to perform. Defaults to None.\n","\n","        Returns:\n","            None\n","        \"\"\"\n","        num_texts = len(texts)\n","\n","        if num_leaves is None:\n","          num_leaves = num_texts\n","        if num_leaves_to_search is None:\n","          num_leaves_to_search = num_texts\n","        if training_sample_size is None:\n","          training_sample_size = num_texts\n","        if reorder_count is None:\n","          reorder_count = num_texts\n","\n","        embeddings = self._embedding_function.embed_documents(list(texts))\n","        embeddings = self.embed_texts(texts)\n","        normalized_embeddings = embeddings / np.linalg.norm(embeddings, axis=1)[:, np.newaxis]\n","\n","        # use scann.scann_ops.build() to instead create a TensorFlow-compatible searcher\n","        self._searcher = (\n","            scann.scann_ops_pybind.builder(normalized_embeddings, num_neighbors, distance_function)\n","            .tree(\n","                num_leaves=num_leaves,\n","                num_leaves_to_search=num_leaves_to_search,\n","                training_sample_size=training_sample_size,\n","            )\n","            .score_ah(\n","                dimensions_per_block,\n","                anisotropic_quantization_threshold=anisotropic_quantization_th)\n","            .reorder(reorder_count)\n","            .build()\n","        )\n","\n","        if self.verbose is True:\n","          print(\"ScaNN vector store is indexed and loaded. ‚úì\")\n","\n","    @classmethod\n","    def from_texts(\n","        cls: Type[VectorStore],\n","        texts: Iterable[str],\n","        embedding: Optional[Embeddings] = None,\n","        max_embedding_requests_per_min: int = 300,\n","        num_neighbors: int = 10,\n","        distance_function: str = \"dot_product\",\n","        num_leaves: Optional[int] = None,\n","        num_leaves_to_search: Optional[int] = None,\n","        training_sample_size: Optional[int] = None,\n","        dimensions_per_block: int = 2,\n","        anisotropic_quantization_th: Optional[float] = 0.2,\n","        reorder_count: Optional[int] = None,\n","        verbose: bool = True,\n","        **kwargs: Any,\n","    ) -> VectorStore:\n","        \"\"\"\n","        Create a ScaNN vector store from a list of texts.\n","\n","        Args:\n","            texts (Iterable[str]): Texts to add to the vectorstore.\n","            embedding (Optional[Embeddings], optional): Embeddings to use for the vectorstore. Defaults to None.\n","            max_embedding_requests_per_min (int, optional): Maximum number of embedding requests per minute. Defaults to 500.\n","            num_neighbors (int, optional): Number of neighbors to consider during partitioning. Defaults to 10.\n","            distance_function (str): Distance function to use. Defaults to \"dot_product\".\n","            num_leaves (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            num_leaves_to_search (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            training_sample_size (Optional[int], optional): Number of documents to use for training. Defaults to None.\n","            dimensions_per_block (int, optional): Number of dimensions per block. Defaults to 2.\n","            anisotropic_quantization_th (Optional[float], optional): Anisotropic quantization threshold. Defaults to 0.2.\n","            reorder_count (Optional[int], optional): Number of reorders to perform. Defaults to None.\n","            verbose (bool, optional): Verbosity. Defaults to True.\n","        Returns:\n","            scann_store: ScaNN vectorstore.\n","        \"\"\"\n","        # create scann store\n","        scann_store = cls(\n","            embedding_function=embedding,\n","            max_embedding_requests_per_min=max_embedding_requests_per_min,\n","            verbose=verbose)\n","\n","        # add texts to scann score\n","        scann_store.add_texts(\n","            texts=texts,\n","            num_neighbors=num_neighbors,\n","            distance_function=distance_function,\n","            num_leaves=num_leaves,\n","            num_leaves_to_search=num_leaves_to_search,\n","            training_sample_size=training_sample_size,\n","            dimensions_per_block=dimensions_per_block,\n","            anisotropic_quantization_th=anisotropic_quantization_th,\n","            reorder=reorder_count,\n","        )\n","        return scann_store\n","\n","\n","    @classmethod\n","    def from_documents(\n","        cls: Type[VectorStore],\n","        documents: List[Document],\n","        embedding: Optional[Embeddings] = None,\n","        max_embedding_requests_per_min: int = 300,\n","        num_neighbors: int = 10,\n","        distance_function: str = \"dot_product\",\n","        num_leaves: Optional[int] = None,\n","        num_leaves_to_search: Optional[int] = None,\n","        training_sample_size: Optional[int] = None,\n","        dimensions_per_block: int = 2,\n","        anisotropic_quantization_th: Optional[float] = 0.2,\n","        reorder_count: Optional[int] = None,\n","        verbose: bool = True,\n","        **kwargs: Any,\n","    ) -> VectorStore:\n","        \"\"\"\n","        Create a ScaNN vector store from a list of documents.\n","\n","        Args:\n","            documents (List[Document]): Documents to add to the vectorstore.\n","            embedding (Optional[Embeddings], optional): Embeddings to use for the vectorstore. Defaults to None.\n","            max_embedding_requests_per_min (int, optional): Maximum number of embedding requests per minute. Defaults to 500.\n","            num_neighbors (int, optional): Number of neighbors to consider during partitioning. Defaults to 10.\n","            distance_function (str): Distance function to use. Defaults to \"dot_product\".\n","            num_leaves (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            num_leaves_to_search (Optional[int], optional): Number of leaves to search. Defaults to None.\n","            training_sample_size (Optional[int], optional): Number of documents to use for training. Defaults to None.\n","            dimensions_per_block (int, optional): Number of dimensions per block. Defaults to 2.\n","            anisotropic_quantization_th (Optional[float], optional): Anisotropic quantization threshold. Defaults to 0.2.\n","            reorder_count (Optional[int], optional): Number of reorders to perform. Defaults to None.\n","            verbose (bool, optional): Verbosity. Defaults to True.\n","        Returns:\n","            scann_store: ScaNN vectorstore.\n","        \"\"\"\n","        texts = [doc.page_content for doc in documents]\n","        return cls.from_texts(\n","            texts=texts,\n","            embedding=embedding,\n","            max_embedding_requests_per_min=max_embedding_requests_per_min,\n","            num_neighbors=num_neighbors,\n","            distance_function=distance_function,\n","            num_leaves=num_leaves,\n","            num_leaves_to_search=num_leaves_to_search,\n","            training_sample_size=training_sample_size,\n","            dimensions_per_block=dimensions_per_block,\n","            anisotropic_quantization_th=anisotropic_quantization_th,\n","            reorder_count=reorder_count,\n","            verbose=verbose\n","        )\n","\n","    def similarity_search(\n","        self,\n","        query: str,\n","        k: Optional[int] = None,\n","        **kwargs: Any,\n","    ) -> List[Document]:\n","        \"\"\"\n","        Run similarity search with ScaNN\n","\n","        Args:\n","            query (str): Query text to search for.\n","            k (Optional[int]): Number of results to return. Defaults to 4.\n","\n","        Returns:\n","            List[Document]: List of documents most similar to the query text.\n","            distances (List[float]): List of distances to the query text.\n","        \"\"\"\n","        query = self._embedding_function.embed_query(query)\n","        neighbors, distances = self._searcher.search(query, final_num_neighbors=k)\n","        return neighbors, distances"],"metadata":{"id":"4RVOOC8oIpBI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Input document source(s)\n","\n","GCS URIs and public website URLs to files in the following formats are supported:\n","* PDF\n","* Images (e.g. tiff, jpeg, png, bmp, webp)\n","\n","Doc AI has a default online requests per minute [quota](https://cloud.google.com/document-ai/quotas) of __120__."],"metadata":{"id":"hy7Z66kyxF9W"}},{"cell_type":"code","source":["from google.cloud import storage\n","\n","def list_all_files(gcs_url):\n","    \"\"\"Lists all the files (blobs) in a GCS bucket.\"\"\"\n","\n","    import re\n","    matches = re.match(r\"gs://(.*?)/(.*)\", gcs_url)\n","\n","    bucket_name = None\n","    folder_prefix = None\n","    if matches:\n","      bucket_name, folder_prefix = matches.groups()\n","\n","    storage_client = storage.Client()\n","    bucket = storage_client.bucket(bucket_name)\n","\n","    blobs = bucket.list_blobs()  # Get an iterator of all blobs\n","\n","    # Create an empty set\n","    my_set = set()\n","\n","\n","    for blob in blobs:\n","      if blob.name.startswith(folder_prefix) and not blob.name.endswith(\"/\"):\n","        my_set.add(f\"gs://{bucket_name}/{blob.name}\")\n","\n","        # print(f\"{bucket_name}\")\n","        # print(f\"{folder_prefix}\")\n","        # print(f\"{blob.name}\")\n","        # print(f\"gs://{bucket_name}/{blob.name}\")\n","\n","    return list(my_set)\n","# Replace with your actual bucket name\n","sources = list_all_files(GCS_URL)[1:2]"],"metadata":{"id":"j6NyrqGIumCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docai_loader = DocAILoader(sources=sources, project_id=PROJECT_ID, max_doc_ai_requests_per_min=110)"],"metadata":{"id":"IrYTQqQsxqJ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documents, images = docai_loader.load()"],"metadata":{"id":"8h90MTNpB6RH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.cloud import aiplatform_v1beta1 as aiplatform\n","def fetch_model(project_id, location):\n","    # Initialize the AIPlatform v1beta1 client (Vertex AI)\n","    client_options = {\"api_endpoint\": f\"{location}-aiplatform.googleapis.com\"}\n","    client = aiplatform.ModelServiceClient(client_options=client_options)\n","\n","    # Construct the parent resource name\n","    parent = f\"projects/{project_id}/locations/{location}\"\n","\n","    # Define a filter to list only tuned models (Modify the filter if needed)\n","    filter = 'labels.google-vertex-llm-tuning-base-model-id:*'\n","\n","    # Prepare the request\n","    request = aiplatform.ListModelsRequest(parent=parent, filter=filter)\n","\n","    # Call the API to list models\n","    response = client.list_models(request=request)\n","    tuned_model = response.models[0]\n","\n","    return tuned_model"],"metadata":{"id":"lYP0IIb-P5VE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vertexai.init(project=PROJECT_ID, location=REGION)\n","deployed_model = fetch_model(PROJECT_ID, REGION)\n","\n","print(deployed_model.display_name)\n","print(deployed_model)"],"metadata":{"id":"9seDQ9kC7n4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.llms import BaseLLM, VertexAI\n","\n","# Construct the tuned model resource name\n","model_name=deployed_model.name\n","\n","llm = VertexAI(\n","  tuned_model_name=model_name,\n","  max_output_tokens=max_output_tokens,\n","  temperature=temperature,\n","  top_p=top_p,\n","  top_k=top_k,\n","  verbose=verbose\n",")\n","\n","\n"],"metadata":{"id":"z8k5cRu1Wxg1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create vector store"],"metadata":{"id":"62iEnbWaxvzf"}},{"cell_type":"markdown","source":["### Option #1: ScaNN"],"metadata":{"id":"Pssil0wW1nBl"}},{"cell_type":"code","source":["vector_store = ScaNN.from_documents(documents)"],"metadata":{"id":"PwTULcY-ysdh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Option #2: Vector Store\n","\n","See [here](https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/matchingengine) for LangChain quick start on using Vertex AI Matching Engine as vector store.\n","\n","Uncomment below to use Matching Engine vector store.\n"],"metadata":{"id":"q69g193-1xT0"}},{"cell_type":"code","source":["# gcs_bucket = \"\" #@param {type:\"string\"}\n","# index_id = \"\" #@param {type:\"string\"}\n","# endpoint_id = \"\" #@param {type:\"string\"}"],"metadata":{"id":"oWARQr0N2T9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# texts = [document.page_content for document in documents]"],"metadata":{"id":"NUsHG2uz1-lI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vector_store = MatchingEngine.from_components(\n","#       texts=texts,\n","#       project_id=PROJECT_ID,\n","#       region=REGION,\n","#       gcs_bucket_uri=gcs_bucket,\n","#       index_id=index_id,\n","#       endpoint_id=endpoint_id,\n","# )"],"metadata":{"id":"lI0BWh0XY7r9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Perform Retrieval QA\n","\n","Define the following:\n","* Prompt template\n","* LLM Model\n","* Answer template"],"metadata":{"id":"3yjHcd_xyBUK"}},{"cell_type":"code","source":["class DocumentBot:\n","  \"\"\"\"\n","  A bot that can answer questions about documents.\n","  \"\"\"\n","\n","  def __init__(\n","      self,\n","      documents: List[Document],\n","      images: dict[Tuple[str, str]: bytes],\n","      vector_store: VectorStore,\n","      llm: BaseLLM,\n","      answer_template: str,\n","      prompt: Optional[PromptTemplate] = None,\n","      signed_url_target_scopes: Optional[List[str]] = None,\n","      signing_service_account: Optional[str] = None,\n","      signing_service_account_credentials_lifetime: int = 300,\n","      signed_url_mins_to_expiration: int = 15,\n","      verbose: bool = True\n","    ) -> None:\n","    self.documents = documents\n","    self.images = images\n","    self.vector_store = vector_store\n","    self.llm = llm\n","    self.answer_template = answer_template\n","    self.prompt = prompt\n","\n","    if signed_url_target_scopes is None:\n","      signed_url_target_scopes = ['https://www.googleapis.com/auth/devstorage.read_only']\n","    self.signed_url_target_scopes = signed_url_target_scopes\n","    self.signing_service_account = signing_service_account\n","    self.signing_service_account_credentials_lifetime = signing_service_account_credentials_lifetime\n","    self.signed_url_mins_to_expiration = signed_url_mins_to_expiration\n","\n","    self.verbose = verbose\n","\n","    self.chain = load_qa_chain(self.llm, chain_type=\"stuff\", prompt=self.prompt)\n","\n","  def _get_qa_chain_output(self, query) -> Tuple[dict[str: Any], List[float]]:\n","    \"\"\"\n","    Get the output of the QA chain for a given query.\n","\n","    Args:\n","        query (str): Query text to search for.\n","\n","    Returns:\n","        dict[str: Any]: Output of the QA chain.\n","        distances (List[float]): List of distances to the query text.\n","    \"\"\"\n","    # get nearest neighbors and distances\n","    neighbors, distances = vector_store.similarity_search(query, k=5)\n","    matching_documents = [self.documents[i] for i, distance in zip(neighbors, distances)]\n","    output = self.chain({\"input_documents\": matching_documents, \"question\": query})\n","    return output, distances\n","\n","  def _process_gcs_uri(self, uri: str) -> Sequence[str]:\n","      \"\"\"\n","      Deconstruct GCS URI into scheme, bucket, path and file\n","\n","      Args:\n","          uri (str): GCS URI\n","\n","      Returns:\n","          scheme (str): URI scheme\n","          bucket (str): URI bucket\n","          path (str): URI path\n","          filename (str): URI file\n","      \"\"\"\n","      url_arr = uri.split(\"/\")\n","      if \".\" not in url_arr[-1]:\n","          filename = \"\"\n","      else:\n","          filename = url_arr.pop()\n","      scheme = url_arr[0]\n","      bucket = url_arr[2]\n","      path = \"/\".join(url_arr[3:])\n","      path = path[:-1] if path.endswith(\"/\") else path\n","      return scheme, bucket, path, filename\n","\n","  def _generate_download_signed_url_v4(\n","      self,\n","      bucket_name: str,\n","      blob_name: str,\n","      target_credentials: impersonated_credentials.Credentials,\n","  ) -> str:\n","    \"\"\"\n","    Generates a v4 signed URL for downloading a blob.\n","\n","    Args:\n","        bucket_name (str): Bucket name.\n","        blob_name (str): Blob name.\n","        target_credentials (impersonated_credentials.Credentials): Target credentials.\n","\n","    Returns:\n","        str: Signed URL.\n","    \"\"\"\n","    storage_client = storage.Client()\n","    bucket = storage_client.bucket(bucket_name)\n","    blob = bucket.blob(blob_name)\n","\n","    url = blob.generate_signed_url(\n","        version=\"v4\",\n","        expiration=datetime.timedelta(minutes=self.signed_url_mins_to_expiration),\n","        method=\"GET\",\n","        credentials=target_credentials\n","    )\n","\n","    return url\n","\n","  def _get_formatted_sources(\n","      self,\n","      output,\n","      distances,\n","      gradio_format: bool = False,\n","      serve_signed_urls: bool = True\n","  ) -> List[str]:\n","    \"\"\"\n","    Format the sources.\n","\n","    Args:\n","        output (dict[str: Any]): Output of the QA chain.\n","\n","    Returns:\n","        List[str]\n","    \"\"\"\n","    # initialize empty formatted sources\n","    formatted_sources = []\n","\n","    # get credentials\n","    credentials, _ = default()\n","\n","    # get target credentials\n","    target_credentials = impersonated_credentials.Credentials(\n","        source_credentials=credentials,\n","        target_principal=self.signing_service_account,\n","        target_scopes=self.signed_url_target_scopes,\n","        lifetime=self.signing_service_account_credentials_lifetime\n","    )\n","\n","    for index, input_document in enumerate(output[\"input_documents\"]):\n","      page_number = input_document.metadata[\"page\"]\n","      source = input_document.metadata[\"source\"]\n","      source = f'{source}#page={page_number}' if page_number else source\n","      signed_url = source\n","\n","      # if GCS URI, get signed url\n","      if source.startswith(\"gs://\") and serve_signed_urls:\n","        scheme, bucket_name, path, filename = self._process_gcs_uri(input_document.metadata[\"source\"])\n","\n","        signed_url = self._generate_download_signed_url_v4(\n","            bucket_name=bucket_name,\n","            blob_name=os.path.join(path, filename),\n","            target_credentials=target_credentials,\n","        )\n","        signed_url += f\"#page={page_number}\" if page_number else signed_url\n","\n","\n","      similarity = distances[index]\n","      if index == 0 and not gradio_format:\n","        top_reference = \"* page: {page}, relevance to answer: {similarity:.2f}\\n\"\n","        top_reference += \"* [{source}]({signed_url})\"\n","        top_reference = top_reference.format(\n","          page=page_number,\n","          source=source,\n","          signed_url=signed_url,\n","          similarity=similarity\n","        )\n","        formatted_sources.append(top_reference)\n","\n","      if gradio_format:\n","        reference = '<p><b>{index}</b>. <a href=\"{signed_url}\">{source}</a>, relevance to question: {similarity:.2f}</p>'\n","        reference = reference.format(\n","          index=index + 1,\n","          source=source,\n","          signed_url=signed_url,\n","          similarity=similarity\n","        )\n","      else:\n","        reference = \"* [{source}]({signed_url})\\n\\t* page: {page}, relevance to question: {similarity:.2f}\"\n","        reference = reference.format(\n","            page=page_number,\n","            source=source,\n","            signed_url=signed_url,\n","            similarity=similarity\n","        )\n","      formatted_sources.append(reference)\n","\n","    return formatted_sources\n","\n","\n","  def answer(self, query: str, serve_signed_urls: bool = False) -> None:\n","    \"\"\"\n","    Get Answer from QA chain.\n","\n","    Args:\n","        query (str): Query text to search for.\n","        serve_signed_urls (bool): Whether to serve signed urls.\n","\n","    Returns:\n","      output (dict[str: Any]): Output of the QA chain.\n","    \"\"\"\n","    output, distances = self._get_qa_chain_output(query)\n","    answer = output[\"output_text\"]\n","    output, distances = self._get_qa_chain_output(answer)\n","\n","    if self.verbose is True:\n","      # get formatted sources\n","      formatted_sources = self._get_formatted_sources(\n","          output, distances,\n","          serve_signed_urls=serve_signed_urls\n","      )\n","\n","      # format answer\n","      answer_str = self.answer_template.format(\n","          question=query,\n","          output_text=answer,\n","          top_reference=formatted_sources[0],\n","          sources='\\n'.join(formatted_sources[1:])\n","      )\n","\n","      # display answer\n","      IPython.display.display(IPython.display.Markdown(answer_str))\n","\n","      # display image\n","      top_source = output[\"input_documents\"][0].metadata[\"source\"]\n","      top_page = output[\"input_documents\"][0].metadata[\"page\"]\n","      top_vertices = output[\"input_documents\"][0].metadata[\"vertices\"]\n","      top_vertices = pd.DataFrame(top_vertices).stack().values.tolist()\n","      image = PIL.Image.open(BytesIO(self.images[(top_source, top_page)]))\n","      PIL.ImageDraw.Draw(image).polygon(top_vertices, outline = 'green', width=5)\n","      IPython.display.display(image.resize((800, 1000)))\n","    return output\n","\n","\n","  def gradio_answer(self, query: str, serve_signed_urls: bool = False) -> None:\n","    \"\"\"\n","    Get answer formatted for gradio\n","\n","    Args:\n","        query (str): Query text to search for.\n","        serve_signed_urls (bool): Whether to serve signed urls.\n","\n","    Returns:\n","      output (dict[str: Any]): Output of the QA chain.\n","    \"\"\"\n","    output, distances = self._get_qa_chain_output(query)\n","    answer = output[\"output_text\"]\n","    output, distances = self._get_qa_chain_output(answer)\n","\n","    # get formatted sources\n","    formatted_sources = self._get_formatted_sources(\n","        output, distances,\n","        gradio_format=True,\n","        serve_signed_urls=serve_signed_urls\n","    )\n","    formatted_sources = '</br>'.join(formatted_sources)\n","    top_source = output[\"input_documents\"][0].metadata[\"source\"]\n","    top_page = output[\"input_documents\"][0].metadata[\"page\"]\n","    top_vertices = output[\"input_documents\"][0].metadata[\"vertices\"]\n","    top_vertices = pd.DataFrame(top_vertices).stack().values.tolist()\n","    image = PIL.Image.open(BytesIO(self.images[(top_source, top_page)]))\n","    PIL.ImageDraw.Draw(image).polygon(top_vertices, outline = 'green', width=5)\n","    return answer, image, formatted_sources, round(distances[0], 3)"],"metadata":{"id":"sYMDBrQbhhbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_template = \"\"\"\\\n","Give a detailed and comprehensive answer to the question using information from the provided contexts. Be sure to provide all details that a user would like to take action on the answer.\n","\n","Evaluate which contexts are most relevant and prioritize comprehensively capturing their details in your response.\n","\n","{context}\n","\n","Question:\n","{question}\n","\n","Helpful Answer and Explanation:\n","\"\"\"\n","prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"],"metadata":{"id":"LIo1bziuWqLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["answer_template = \"\"\"\\\n","## Response\n","### Question\n","{question}\n","### Answer\n","{output_text}\n","### Why\n","{top_reference}\n","\n","### Sources\n","{sources}\n","\"\"\""],"metadata":{"id":"RcaaSSYYhbnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["document_bot = DocumentBot(\n","  documents=documents,\n","  images=images,\n","  vector_store=vector_store,\n","  llm=llm,\n","  prompt=prompt,\n","  answer_template=answer_template,\n","  signing_service_account=GOOGLE_CLOUD_SERVICE_ACCOUNT,\n","  #signing_service_account_private_key=GOOGLE_APPLICATION_CREDENTIALS\n",")"],"metadata":{"id":"i1q5eoQrXhvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ask a Question\n","\n","Note: it takes a few seconds more (e.g. 2-8 secs) ‚åõ to serve signed urls for the GCS quick links. If solely trying to evaluate speed,  set _serve_signed_urls_ to False. This parameter does not have an effect either way on public documents."],"metadata":{"id":"mMG9IGwcV4ZB"}},{"cell_type":"markdown","source":["### Gradio\n","\n","Lightweight UI for document search and summarization."],"metadata":{"id":"9rpk9QQhYl4c"}},{"cell_type":"code","source":["with gr.Blocks() as demo:\n","    gr.Markdown(\n","    \"\"\"\n","    ## Document Search\n","\n","    This demo showcases document search of input documents using Document AI üìëüëÄ + LangChain ü¶úÔ∏èüîó + ScaNN / Matching Engine üß©üîç.\n","\n","    \"\"\")\n","    with gr.Row():\n","      with gr.Column():\n","        query = gr.Textbox(label=\"Query\", placeholder=\"Enter a question\")\n","\n","    with gr.Row():\n","      generate = gr.Button(\"Answer\")\n","\n","    gr.Markdown(\n","    \"\"\"\n","    ## Summary\n","    \"\"\")\n","    with gr.Row():\n","      answer_label = gr.Textbox(label=\"Response\")\n","\n","    image = gr.Image(type=\"pil\")\n","\n","    with gr.Row():\n","      confidence_score = gr.Textbox(label=\"Confidence\")\n","\n","    gr.Markdown(\n","    \"\"\"\n","    ## Sources\n","    \"\"\")\n","    with gr.Row():\n","      sources = gr.HTML(label=\"Sources\")\n","\n","    generate.click(document_bot.gradio_answer, query, [answer_label, image, sources, confidence_score])\n","\n","demo.launch(share=False, debug=False)"],"metadata":{"id":"9fOW4WzTYgSf"},"execution_count":null,"outputs":[]}]}